# AI-Powered-Autonomous-Driving-System-Using-Deep-Learning-Simulation
Our project centers on building an advanced AI-based autonomous driving system using the AirSim NH (Neighborhood) simulator developed by Microsoft. We utilized Unreal Engine 4.27 to create a photorealistic environment where the car could learn and operate in a wide variety of urban driving scenarios. To control the simulation environment, we created detailed CSON files that define elements such as car spawn points, traffic density, pedestrian movement, and weather conditions. These were converted into JSON format that AirSim could interpret and use to load dynamic, customizable scenarios.

We integrated a range of sensors using AirSim’s API, including multiple RGB cameras, depth sensors, IMUs, and GPS, capturing real-time visual and telemetry data. During simulation, this data was logged at regular intervals and stored in structured datasets—images in folders and numerical data like speed, angle, and position in CSV format. Segmentation data and depth information were also recorded to help the model learn the physical layout of roads, sidewalks, and other objects.

We processed this data to create a clean, balanced dataset, applying transformations and augmentations such as flips and brightness variations to simulate diverse lighting and weather conditions. We then trained a deep neural network consisting of convolutional layers for visual understanding, followed by fully connected layers to predict control outputs—steering angle, acceleration, and braking pressure. The model was optimized using the Adam optimizer with learning rate decay and regularization to avoid overfitting.

Once trained, the model was deployed inside the AirSim environment for real-time inference. It captured live video input from the front camera, processed it through the model, and translated the output into car control commands. To ensure smooth driving, we wrapped the model’s output in a PID control mechanism that corrected jerky or abrupt movements. The car was able to drive through complex environments, adjust to weather, avoid obstacles, and make realistic driving decisions in real time.

Overall, the project demonstrates a full pipeline—from simulation and scenario design with CSON and JSON, through data collection and model training, to live deployment in a 3D simulation. It showcases how deep learning and reinforcement mechanisms can work together to mimic human driving behavior accurately and adaptively.
